---
title: "MADA Project"
author: "Joe Martin"
date: "10/8/2021"
output: pdf_document
---
```{r echo=FALSE}
pacman::p_load(tidyverse,tidymodels,here)

run_journal <- readRDS(here::here("data","processed_data","run_data_clean.rds"))
garmin <- readRDS(here::here("data","processed_data","garmin_data.rds"))
rhr <- read_csv(here::here("data","raw_data", "dailyRHR.csv"))
```

## Part 1 - Background

Marathon and distance running culture revolves heavily around one goal – qualifying for the Boston Marathon. It’s so important to distance runners that it’s become a verb (ex. I’m ready for my next race. I think I might even BQ). Even outside of qualifying for the Boston Marathon, the point of training for races is improving personal records and achieving new goals. For many distance runners and other endurance athletes, great care and attention to detail is taken when preparing for a race and choosing the right race. Race organizers tend to post information about their courses like elevation, ascent, descent, and more. Some go as far as designing courses that are AATF certified and net-down-hill to allow for faster course times. 

Over the last several years, fitness watches provided endurance athletes with new ways to track their training without the need to hire coaches or fancy equipment and tests, like chest-strap heart rate monitors, VO2 Max tests, or lactate threshold finger-prick tests. Models like the Garmin Forerunner 245 (the smart watch used in this project) have even been found to accurately estimate VO2 Max and lactate threshold with just the optical heartrate sensor. 

Given the need desire marathoners have to maximize their race experience, invest the right amount of time and money training and registering for a race, it would make sense that all of this data could be utilized in a model that would predict race outcomes. Runners easily have access to their own information – heart rate, average pace, ascent and descent of training runs. They also have data about the location of their training runs – elevation, weather conditions, and temperature. Adding all of these variables into a supervised learning model could help a runner search for a course that would perfectly suit their needs and abilities. 

The goal of this project is to create a model which, when deployed, can take in variables of a potential race course – elevation, length, temperature, and weather conditions – and variables from the athlete – current resting heart rate, average heart rate during training, stride length, cadence, etc. – and predict the athlete’s average pace. 
 

## Methodology
### Data

The data used for this model comes from my Garmin Forerunner 245 and run journal. The final data set contains 417 observations and more than 20 variables. Variables include date, distance, weather (temperature and conditions), total ascent, total descent, min elevation, max elevation, cadence, average stride length, and average pace. Much of this data is replicated in my running journal. While my running journal isn't included in the model, it was used in my data exploration and pieces of it were joined with my final model set. 

##### Running Journal
```{r}
glimpse(run_journal)

head(run_journal)
```

##### Garmin Data
```{r}
glimpse(garmin)

head(garmin)
```

### Data Preparation

Early in my project, I started using data from the years 2013-2019. Initially, I thought it would be possible to model performance over time. During this period, however, I did not record my runs on a smart watch, so many of the necessary variables do not exist in this dataset. During the data preparation phase, I cleaned datasets which included data from the period 2013-2019. This data is included in the data preparation files and used in the exploratory analysis, but is not used for modeling. 

The data sets available had more data and fields than necessary. The initial steps involved cleaning and tidying data, then joining the primary data sets together. Much of this work was focused on eliminating variables that were not related to running (swimming and cycling data), then ensuring that data from my run journal shared a unique identifier with my Garmin data to join on.

## Part 2 - Data Cleaning and Exploration

Instructions for reproducing my data cleaning and exploration process are in found in the `readme.md` file in the data folder. To reproduce code from Part 2 of this project, execute the script `mada_project_part2.R` located in `~code/processing_code`. After executing this script, the figures below can be reproduced by executing the script `exploratory_analysis.R` in `~/code/analysis_code`.

### Data Cleaning

This stage of my project began with loading my raw data directly from the Google sheets I use with the `googlesheets4` package. This is mentioned in the notes of my script, but no longer visible. The `googlesheets4` package gives the ability to write to a googlesheet, so I thought it could be risky if I potentially gave that ability to anyone accessing my GitHub. Files for years 2013-2021 were loaded and saved as .rds files before processing. I left a line of code commented out so I'm able to paste in my Google sheet for year 2021 and update data frequently. At this stage, I also imported data from my Garmin Connect account for all of my runs since April 2020, as well as my resting heart rate data.

Over the years, some variables mattered to me and others didn't, so I began cleaning by removing variables that no longer seem to serve a purpose or have a small amount of data during one period of time. 

Once I cleaned out the variables I didn't want, my data files had consistent column structure from 2013-2021. I coerced the data type of variables just enough so I could bind all of this data together.

My plan moving into data analysis is to keep a separate dataframe for my run journal data (2013-present), my Garmin data, and my resting heart rate. When I want to work with variables across each set, I will join them together. 

To complete my data cleaning, I coerced each variable into its necessary type. The most challenging variable has proven to be average pace. This is likely one of the most important variables in my set (if not <em>the</em> most important), so I may need to rethink how I'm using this variable going forward. I ultimately ended by coercing it, as well as best_pace in the Garmin data set, using `as.POSIXct()`. This is not ideal because `as.POSIXct()` also assigns a date value. However, this was good enough to begin analysis. 
Following processing, clean datasets were saved as rds files in `~/data/processed_data`. Notably, I saved two versions of my journal data - one set eliminates NAs for days I didn't run (1,202 observations), one of them retains them (more than 3,000 observations). The purpose of this was to retain notes I kept on days I did not run. 

## Part 3 - Exploratory Analysis

My exploratory analysis began primarily using the `lm()` function to see if any variables are highly correlated. I graphed these, as well, in order to better visualize this relationship. Unfortunately, `lm()` does not support date data and time data, therefore, could not give me useful information about correlations. From this experience, I decided to change my average pace variable from hms format to seconds, measured as a numeric value.

I purposely chose variables I anticipated would have significant p-values. I wanted to understand which variables would be most important to my future analysis and modeling, especially if I can introduce new variables, like miles per week and shoes.

The plots below were generated with the `exploratory_analysis.R` script.

### Relationships

#### Average Pace
Average pace is crucial to many of my analyses. Going forward, I will work on finding a better way to coerce this data into a time format that's usable in statistical models.

Over the past 8 years, my overall average pace has decreased, despite my increase in true recovery runs this year. A recovery run is a very easy run where my heart rate stays in or below Zone 3.
```{r average_pace_1321}
average_pace_1321 <- run_journal %>% ggplot(aes(x=date, y= avg_pace_sec))+
  geom_point()+
  geom_smooth(method = "lm")
average_pace_1321
```

For a better measure of my performance, I'll look at my longer distance runs - anything over 12 miles. The pace for these runs has decreased over time. 
```{r ld}
# Long Disance Runs
ld <- run_journal %>%
  filter(distance >= 12) %>%
  filter(date >= "2018-01-01") %>%
  ggplot(aes(x=date,y=avg_pace_sec))+
  geom_point()+
  geom_smooth(method = "lm")

ld
```

Cadence is the measure of how many times a runner's feet hit the ground per minute. A high cadence is typically associated with a faster pace. 
```{r cad_ap}
# Effect of Cadence on Average Pace
cad_ap <-garmin %>% ggplot(aes(x=avg_run_cadence, y=avg_pace_sec))+
  geom_point()+
  geom_smooth(method = "lm")

cad_ap
```

Aerobic TE is a measurement Garmin created to rate an aerobic effort. On a scale from 1-5, 5 is a maximum effort. This is good stress for the body, but requires a lot of rest time afterwards. 1 is minimal and typically associated with other types of exercise besides running. This 
```{r ae_ap}
# Effect of Harder Aerobic Effort on Average Pace
ae_ap<- garmin %>% ggplot(aes(x=aerobic_TE, y=avg_pace_sec))+
  geom_point()+
  geom_smooth(method = "lm")

ae_ap
```

Average heart rate may be another important variable in my project.
```{r hr_ap}
# Average Pace and Average Heart Rate
hr_ap <- garmin %>% ggplot(aes(x=avg_hr, y = avg_pace_sec))+
  geom_point()+
  geom_smooth(method = "lm")

hr_ap
```

Greater stride length seems to be associated with a greater pace. This seems counter-intuitive if thinking about cadence in this equations, but with good form and mechanics, greater cadence is more likely to be associated with greater stride length.
```{r st_ap}
# Stride and Average Pace
st_ap <- garmin %>% ggplot(aes(x=avg_stride, y = avg_pace_sec))+
  geom_point()+
  geom_smooth(method = "lm")

st_ap
```

#### Other important variables

Correlation between cadence and stride
```{r cadence_stride}
ca_stride <- garmin %>% ggplot(aes(x=avg_run_cadence, y=avg_stride))+
  geom_point()+
  geom_smooth(method = "lm")

ca_stride
```

Living in the Southern US, we have to deal with high temperatures. Marathons typically aren't held in the summer for a reason. Excessive heat is not only known to decrease performance, but can be dangerous. Although it can't be totally avoided, I try not to run when it's too hot out.

However, it seems that weather doesn't seem to have a major influence on my performance. I expected to see a steep incline from the origin to the end of the plot. This could possibly be explained by my training cycle. Colder months tend to be my "off-season" where I maintain fitness. Running races in the beginning of the winter, I do very little hard training in the cold.
```{r temp_pace}
# Temperature
# I'm less likely to run far when it gets hot out. 
fit1 <- lm(avg_pace_sec ~ temperature, run_journal)
summary(fit1)

temp_pace <- run_journal %>% ggplot(aes(x=temperature, y = avg_pace_sec))+
  geom_point()+
  geom_smooth(method = "lm")

temp_pace
```


Hill training is crucial for success in any race and research shows that hill intervals can better prepare runners than any other type of training. As expected, my pace decreases as elevation increases. 
```{r pace_ascent_plot}
#avg_hr, total_ascent
pace_ascent <- lm(avg_pace_sec~total_ascent,garmin)
summary(pace_ascent)

pace_ascent_plot <-garmin %>% ggplot(aes(x=avg_pace_sec, y = total_ascent))+
  geom_point()+
  geom_smooth(method = "lm")

pace_ascent_plot
```

However, the Aerobic Training Effect variable shows that I improve my aerobic training when I run uphill.
```{r ae_ta}
ae_ta <- garmin %>% ggplot(aes(x=aerobic_TE, y=total_ascent))+
  geom_point()+
  geom_smooth(method = "lm")

ae_ta
```

## Statistical Modeling

To reiterate the goal of this paper, I would like to create a model that can predict how I could perform on a given course on a given day. In order to complete this goal, I will need to predict my average pace. Since this is a numeric variable measured only in seconds, I will use a linear regression for this model. 

At the beginning of this project I anticipated having far more data - more than 1000 observations. This decreased to about 420 after deciding only to use data from my smart watch. This is relatively few and 


### Adding New Variables
In "Human running performance from real-world big data," authors Emig and Peltonen create a statistical model based on fields captured by the Polar V800 fitness watch, including measures like <em>p = power, v = velocity, t = time,</em> as well as maximal aerobic power (MAP), VO2 Max, anaerobic endurance. These variables go into their model to predict performance during a marathon. 

Since processing my data for the first time, I found even more measurements I was interested in inspecting on Garmin Connect, the online dashboard which hosts the data from my watch. For some reason, this data is readily available on individual run records in the website dashboard, but not included in any csv files I'm allowed to export. Therefore, I created a new script which uses RSelenium to take this data from Garmin Connect. This adds the variables Anaerobic Training Effect (anaerobic_value), Average Speed (avg_spd), Average Moving Speed(avg_moving_spd), and Maximum Speed (max_spd). Additionally, I added the variable for estimated sweat loss out of curiosity. 

Being unable to access the precise variables Emig and Peltonen describe, I intend to use similar variables to investigate relationships within my dataset. 

### Trying models
Since I'm trying to predict performance, I wanted to see which variables would be best for doing so. I started by seeing if it is possible to use a linear regression to predict pace. In my analysis, the best model I was able to create used all variables and predicted average pace within 5.4 seconds. 


#### Linear Regression

```{r echo=FALSE}
# Load packages and data
pacman::p_load(tidyverse, tidymodels, here)

garmin <- read_rds(here::here("data","processed_data", "garmin_data.rds"))

# Transform data to have only the necessary variables
df <- garmin %>% select(-id,-week, -calories)
```

```{r}
prelim_pace <- lm(avg_pace_sec ~ ., df)
summary(prelim_pace)

```

To begin predicting run performance, an initial linear regression model will be built below using all available data. Based on the preliminary linear regression above, an aerobic training effect that has a high impact (value between 4 and 4.9) is strongly related to average pace. This variable will be the target variable in the logistic regression that follows. 

```{r}
set.seed(456)
# Split data into training and testing sets
df_split <- initial_split(df, prop = 3/4)

train_df <- training(df_split)
test_df <- testing(df_split)

# Create recipe
pace_rec <- recipe(avg_pace_sec ~ ., data = train_df)

summary(pace_rec)
```

```{r}
lm_pace <- linear_reg() %>%
  set_engine("lm")

pace_wflow <- workflow()%>%
  add_model(lm_pace) %>%
  add_recipe(pace_rec)

pace_fit <- pace_wflow %>% 
  fit(data = train_df) 

tidy(pace_fit)
```

```{r}
predict(pace_fit, test_df)
```

```{r}
pace_aug <- augment(pace_fit, test_df)

pace_aug %>% select(avg_pace_sec, .pred)
```

The R Mean-Squared Error for this model is 5.41. In other words, this model can predict average pace within 5.41 seconds.
```{r}
pace_error <- pace_aug %>% 
  rmse(truth = avg_pace_sec, .pred)

pace_error
```

These analyses provide a good starting point for building a more complex model that can predict good performance. The possible next step is to use v-fold cross validation to enhance the quality of my training set. In this section, the random forest model will use k-fold cross validation and train with all variables.
```{r}
pacman::p_load(tidymodels, ranger, parallel)

cores <- parallel::detectCores()

set.seed(456)

# Split data into training and testing sets
df_split <- initial_split(df, prop = 3/4)

train_df <- training(df_split)
test_df <- testing(df_split)

# Create recipe
rf_rec <- recipe(avg_pace_sec ~ ., data = train_df) %>%
          step_dummy(all_nominal_predictors())

folds <- vfold_cv(train_df, v = 10, repeats = 5, strata = avg_pace_sec)

summary(rf_rec)
```

```{r}
rf_mod <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
  set_engine("ranger", num.threads = cores) %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  add_model(rf_mod) %>%
  add_recipe(rf_rec)

rf_res <- rf_wf %>%
  tune_grid(folds,
            grid = 25,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(rmse))
```

```{r}
rf_res %>%
  show_best(metric = "rmse")

autoplot(rf_res)
```

```{r}
rf_best <- rf_res %>%
  select_best(metric = "rmse")
rf_res %>% collect_predictions()
```

```{r}
final_rf_wf <- rf_wf %>%
  finalize_workflow(rf_best)

final_fit_rf <- final_rf_wf %>%
  last_fit(df_split)

final_fit_rf %>% collect_metrics()

rf_rmse <- 
  rf_res %>%
  collect_predictions(parameters = rf_best) %>%
  rmse(avg_pace_sec, .pred) %>%
  mutate(model = "Random Forest")
rf_rmse
```

This model predicts average pace within 4.4 seconds. In an attempt to improve the accuracy, some variables will be eliminated. This model ran with 21 predictors. Thinking about the purpose of this model (predicting potential race pace), there are features in this dataset which might not be available before the race. For example, speed would be related to the target (average pace) and not necessarily available as a predictor. The same goes for sweat loss. Therefore, these features will be removed. 
```{r}
set.seed(456)

#get rid of max_hr,min_elevation, max_elevation, and sweat_loss
df1 <- df %>% select(-max_spd, -avg_spd, -`sweat_loss(ml)`)

# Split data into training and testing sets
df1_split <- initial_split(df1, prop = 3/4)

train_df1 <- training(df1_split)
test_df1 <- testing(df1_split)

# Create recipe
rf_rec <- recipe(avg_pace_sec ~ ., data = train_df1) %>%
          step_dummy(all_nominal_predictors())

folds <- vfold_cv(train_df, v = 10, repeats = 5, strata = avg_hr)

summary(rf_rec)
```

```{r}
rf_mod <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
  set_engine("ranger", num.threads = cores) %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  add_model(rf_mod) %>%
  add_recipe(rf_rec)

rf_res <- rf_wf %>%
  tune_grid(folds,
            grid = 25,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(rmse))
```

```{r}
rf_res %>%
  show_best(metric = "rmse")

autoplot(rf_res)
```

```{r}
rf_best <- rf_res %>%
  select_best(metric = "rmse")
rf_res %>% collect_predictions()
```

```{r}
final_rf_wf <- rf_wf %>%
  finalize_workflow(rf_best)

final_fit_rf <- final_rf_wf %>%
  last_fit(df1_split)

final_fit_rf %>% collect_metrics()

rf_rmse <- 
  rf_res %>%
  collect_predictions(parameters = rf_best) %>%
  rmse(avg_pace_sec, .pred) %>%
  mutate(model = "Random Forest")
rf_rmse
```

The accuracy (measured by RMSE) got worse (7.11). Try dropping more variables. This time, ascent, descent, aerobic factors and anaerobic factors. 


Try running the model with tuned parameters.
```{r}
set.seed(456)

# Split data into training and testing sets
df1_split <- initial_split(df1, prop = 3/4)

train_df1 <- training(df1_split)
test_df1 <- testing(df1_split)

# Create recipe
rf_rec <- recipe(avg_pace_sec ~ ., data = train_df1) %>%
          step_dummy(all_nominal_predictors())

folds <- vfold_cv(train_df, v = 10, repeats = 5, strata = avg_hr)

summary(rf_rec)
```

```{r}
rf_mod <- rand_forest(mtry = 7, min_n = 7, trees = 1000) %>%
  set_engine("ranger", num.threads = cores) %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  add_model(rf_mod) %>%
  add_recipe(rf_rec)

rf_res <- rf_wf %>%
  tune_grid(folds,
            grid = 25,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(rmse))
```

```{r}
rf_res %>%
  show_best(metric = "rmse")
```

```{r}
rf_best <- rf_res %>%
  select_best(metric = "rmse")
rf_res %>% collect_predictions()
```

```{r}
final_rf_wf <- rf_wf %>%
  finalize_workflow(rf_best)

final_fit_rf <- final_rf_wf %>%
  last_fit(df1_split)

final_fit_rf %>% collect_metrics()

rf_rmse <- 
  rf_res %>%
  collect_predictions(parameters = rf_best) %>%
  rmse(avg_pace_sec, .pred) %>%
  mutate(model = "Random Forest")
rf_rmse
```

This final Random Forest model has a greater RMSE value than the previous one. One of the concerns with the dataset is the greater number of features (21 total predictors avialable). LASSO may be a good option to automate feature selection. 
```{r}
set.seed(456)
# Split data into training and testing sets
df_split <- initial_split(df1, prop = 3/4)

train_df <- training(df_split)
test_df <- testing(df_split)

# Create recipe
lasso_rec <- recipe(avg_pace_sec ~ ., data = train_df)

# create folds
folds <- vfold_cv(train_df, v = 10, repeats = 5, strata = avg_hr)

summary(lasso_rec)
```

```{r}
lasso_mod <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("lm")

lasso_wkfl <- workflow() %>%
  add_model(lasso_mod) %>%
  add_recipe(lasso_rec)
```

```{r}
# create penalty grid for tuning
lasso_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))

# lowest penalties
lasso_grid %>% top_n(-5)

#highest penalties
lasso_grid %>% top_n(5)
```

```{r}
lasso_res <- lasso_wkfl %>%
  tune_grid(folds,
            grid = lasso_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(rmse))
```

```{r}
top_models <- lasso_res %>%
  show_best("rmse")
top_models
```

```{r}
lasso_best <- lasso_res %>%
  select_best("rmse")
lasso_best

final_lasso_wf <- lasso_wkfl %>%
  finalize_workflow(lasso_best)

final_lasso_fit <- final_lasso_wf %>%
  last_fit(df_split)

final_lasso_fit %>% collect_metrics()
```

The LASSO model does improve the RMSE and is likely the best path forward. The next steps in this project will be to further tune this model. 

## References

Emig, T., Peltonen, J. Human running performance from real-world big data. Nat Commun 11, 4936 (2020). https://doi.org/10.1038/s41467-020-18737-6

