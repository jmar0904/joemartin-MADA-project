---
title: "MADA Project"
author: "Joe Martin"
date: "10/8/2021"
output: pdf_document
---
# Part 1 - Background

## The Data Set

The data I intend to use for my project is my personal running data. I started distance running in 2012 just before I got my very first smartphone. At the beginning of 2013, I started to track all of my runs in the Nike Run Club app. This was my primary way of tracking my runs. Toward the end of 2014, I started trying various other apps and mostly got the same data out of them. Apps included MapMyRun and Strava, and possibly a few more. Much of my data from 2015 and 2016 is missing and I’m unsure how to, or if I could ever, recover it. In 2017 I mostly used MapMyRun. In 2018, I moved back to  Nike Running and had a full month in 2020 when I used Strava exclusively. In April of 2020, I bought my first smartwatch (a Garmin Forerunner 245), which I’ve been using to track all of my training (running, swimming, and cycling).

I estimate that I have about 1,000 observations for running. In 2020 when we went into lockdown for COVID-19, I began moving all of my data from my various apps and accounts into a Google sheet. I mainly did this manually. I enter my data into another spreadsheet manually for my most recent runs, which I primarily use as my training journal. In this journal, I record imprecise numbers – average pace, mile/lap splits, the shoes I wore, weather, time of day/date, total distance, location of my run, distance type (short, medium, or long), and workout type (recovery, easy, speed, long distance). Along with this, I’ll also take notes about my run, like how I feel, thoughts about how my training is going, whether I’m feeling any pain or note any injuries, etc. With my Garmin watch, I have a Garmin Connect account, which automatically stores my data to the cloud. When I export data related to my activities (running, swimming, and cycling all come together), Garmin gives me a .csv file with 36 variables, although some are empty or have 0 for all values. 

Outside of this data, I also have access to data about my sleep and resting heart rate from my Garmin watch. Sleep data includes how long I slept, how long I spent in light sleep, deep sleep, REM sleep, and my respiration during sleep. Resting heart rate data is included below and shows my resting heart rate for each day. I'm interested in using this data and even reviewing activities outside of running (swimming and cycling) to see if they affect my performance, although I'm also hesitant to start with such a broad scope. 

Going through my data, I have noticed that most of my variables are currently stored as character data. This will be one of the first things I will need to fix to make the most out of my data.

## Raw Data

Data included in this section contains my run logs from 2013 - 2021, as well as my resting heart rate from April 15, 2020 - present. Data I have available for use, but not yet ready to share includes my detailed post-run notes, sleep data, and other random calculations my Garmin watch does for me (VO2 Max, Pulse OX, stress, etc.). I'm leaving these out initially because, while I'm interested in using them, I am also concerned they will greatly broaden the scope and complexity of this project.

#### Historical Data 2013 - 2018
```{r echo=FALSE}
# Load Packages
pacman::p_load(pacman, rio, tidyverse, lubridate, here)

# Load Run Data ############################################
# When adding years 2013-2019, change df1 to df20 and make full dataframe out of all years

# 2013 - 2018 Run Data
data13 <- here::here("data", "raw_data","df1318.rds")
df1318 <- read_rds(data13)

# filter out dates without data
df1318 <- df1318 %>% filter(total_time != '')

```

```{r}
summary(df1318)
```

```{r}
head(df1318)
```

#### Data from 2021

Data from 2019 - 2021 is located in ~/data/raw_data. These sample dataframes are a bit too messy to be useful in this section of the project - primarily because they contain header that are irrelevant. These primarily follow the same format as data from 2013 - 2018. 

```{r echo=FALSE}
data21 <- here::here("data","raw_data", "df2021.rds")

df21 <- read_rds(data21)
```

#### Data from Garmin Forerunner 245
```{r}
garminRun <- here::here("data","raw_data","garmin20210926.csv")
garmin <- read_csv(garminRun)

head(garminRun)
```


#### Resting Heart Rate 4/15/21 - Present
```{r}
rhr_data <- here::here("data","raw_data", "dailyRHR.csv")

rhr <- read_csv(rhr_data)
```

```{r}
summary(rhr)
```

```{r}
head(rhr)
```

## Project Objectives

Through this project, I'm interested in understanding how factors of my training program affect my performance. I would like to see if there are any significant relationships between the frequency or intensity of my training and performance. My outcomes of interest would be finding whether there are significant patterns in my pace, active heart rate, or resting heart rate. I'm also interested in seeing if I can measure qualitative outcomes through the notes I take after each run. Some of the patterns I would look for in my data would include the relationship between a positive performance outcome and variables like shoes, number of speed workouts before a race or a long run, or weekly volume (total weekly mileage or time exercising). 

In order to search for relationships and patterns in my data, I will first need to identify specific events - like races or long runs - and compare weeks of training against each other. For example, I do one long distance run just about every week. I would be interested in understanding if my pace decreases on a long run if I had more active training days leading up to this run. I would want to see if my heart rate during similar runs (for example, long runs on the same route) decreases over time or increases after a break in training. 

The other way I may go about analyzing patterns in my data would be by picking specific distances described the same way (easy, steady, tempo). For example, a common workout for me would be an up-tempo 10k (6.22 miles) or an easy 8-miler. 

Finally, although I have few races in my data set, I do have a good understanding of my training program, which I follow for weeks in advance of a race. For some races, I have a detailed log of this program. I could measure my fitness ahead of a training program and compare it to my fitness just before or at race time. Measurement of fitness would include average pace, heart rate, and perhaps even ratings based on positive or negative notes taken about training sessions. 

## Further Background

Coaches and personal trainers are expensive to hire. Apps provide users with some basic stats about their runs, but users typically have to purchase a subscription to get useful insights into training. Further, apps often use algorithms that do not produce practical insights. For example, Garmin provides users with a Performance Condition measurement. Garmin devices display this measurement to users during a workout to tell them how their performance compares to their average fitness level. Using pace, heart rate, and heart rate variability data, Garmin displays a score from -20 (Poor) to values greater than 10 (Excellent). 

This is just one example of a measurement which ignores natural variability in training sessions and directly contradicts training programs established over decades by expert coaches and researchers, like Pete Pfitzinger and Jack Daniels, PhD. These expert coaches outline training plans which have a general pattern for long distance races, from 5,000 m races, all the way to marathons. This pattern includes two general aerobic runs per week (about 1:00 per mile slower than race pace), one or two speed sessions (lactate threshold runs at race pace, tempo runs, or track intervals), one or two recovery runs (about 2:00 per mile slower than race pace or heart rate in or below Zone 3), and a long distance run. These programs build in rest days, as well, which athletes are supposed to use for recovery or cross training. 

Aggregate fitness data used by companies like Garmin and Polar is useful developing insights into human performance outcomes for the average person, like in "Human running performance from real-world big data" by Thorsten Emig & Jussi Peltonen. Due to the variability in  quality distance training programs, however, aggregate measures and seemingly random algorithms are not useful in helping individual athletes understand whether they're training well.

```{r load_packages_data}
pacman::p_load(pacman, tidyverse, here)

### Load Data ###
run_df <- read_rds(here::here("data","processed_data","run_data_clean.rds"))
garminRun <- read_rds(here::here("data","processed_data","garmin_data.rds"))
rhr <- read_rds(here::here("data","processed_data","resting_heart_rate.rds"))
```

# Part 2 - Data Cleaning and Exploration

Instructions for reproducing my data cleaning and exploration process are in found in the readme.md file in the data folder. To reproduce code from Part 2 of this project, execute the script "mada_project_part2.R" located in "~code/processing_code". After executing this script, the figures below can be reproduced by executing the script "exploratory_analysis.R" in "~/code/analysis_code".

## Data Cleaning

This stage of my project began with loading my raw data directly from the Google sheets I use with the googlesheets4 package. This is mentioned in the notes of my script, but no longer visible. The googlesheets4 package gives the ability to write to a googlesheet, so I thought it could be risky if I potentially gave that ability to anyone accessing my GitHub. Files for years 2013-2021 were loaded and saved as .rds files before processing. I left a line of code commented out so I'm able to paste in my Google sheet for year 2021 and update data frequently. At this stage, I also imported data from my Garmin Connect account for all of my runs since April 2020, as well as my resting heart rate data.

Over the years, some variables mattered to me and others didn't, so I began cleaning by removing variables that no longer seem to serve a purpose or have a small amount of data during one period of time. 

Once I cleaned out the variables I didn't want, my data files had consistent column structure from 2013-2021. I coerced the data type of variables just enough so I could bind all of this data together.

My plan moving into data analysis is to keep a separate dataframe for my run journal data (2013-present), my Garmin data, and my resting heart rate. When I want to work with variables across each set, I will join them together. 

To complete my data cleaning, I coerced each variable into its necessary type. The most challenging variable has proven to be average pace. This is likely one of the most important variables in my set (if not <em>the</em> most important), so I may need to rethink how I'm using this variable going forward. I ultimately ended by coercing it, as well as best_pace in the Garmin data set, using as.POSIXct. This is not ideal because as.POSIXct also assigns a date value. However, this was good enough to begin analysis. 
Following processing, clean datasets were saved as rds files in "~/data/processed_data". Notably, I saved two versions of my journal data - one set eliminates NAs for days I didn't run (1,202 observations), one of them retains them(more than 3,000 observations). The purpose of this was to retain notes I kept on days I did not run. 

## Exploratory Analysis

My exploratory analysis began primarily using the lm() function to see if any variables are highly correlated. I graphed these, as well, in order to better visualize this relationship. Unfortunately, lm() does not support date data and, therefore, could not give me useful information about correlations.

I purposely chose variables I anticipated would have significant p-values. I wanted to understand which variables would be most important to my future analysis and modeling, especially if I can introduce new categorical variables, like miles per week and shoes.

The plots below were generated with the "exploratory_analysis.R" script.

### Relationships

#### Resting Heart Rate

This plot show that my heart rate consistently remains around 47 bpm. There are significant outliers in this data that may skew the results higher. If I don't wear my Garmin watch all day and all night, my resting heart rate can be recorded as 60-70 bpm, which is very unlikely.

In future analyses, it will be interesting to compare this data to variables like weekly training volume, cadence, and average pace.
```{r rhr}
rhr_plot <- rhr %>% ggplot(aes(x=date, y=`rhr(bpm)`))+
  geom_line()+
  geom_smooth(method = "lm")

rhr_plot
```

#### Average Pace
Average pace is crucial to many of my analyses. Going forward, I will work on finding a better way to coerce this data into a time format that's usable in statistical models.

Over the past 8 years, my overall average pace has decreased, depsite my increas in true recovery runs this year. A recovery run is a very easy run where my heart rate stays in or below Zone 3.
```{r average_pace_1321}
average_pace_1321 <- run_df %>% ggplot(aes(x=date, y= avg_pace))+
  geom_point()+
  geom_smooth(method = "lm")
average_pace_1321
```

Over the past 3 years, however, my recovery runs have made my average pace slower.
```{r average_pace_1821}
average_pace_1821 <- run_df %>% filter(date >= "2018-01-01") %>%
  ggplot(aes(x=date,y=avg_pace))+
  geom_point()+
  geom_smooth(method = "lm")

average_pace_1821
```

For a better measure of my performance, I'll look at my longer distance runs - anything over 12 miles. The pace for these runs has decreased over time. 
```{r ld}
# Long Disance Runs
ld <- run_df %>%
  filter(distance >= 12) %>%
  filter(date >= "2018-01-01") %>%
  ggplot(aes(x=date,y=avg_pace))+
  geom_point()+
  geom_smooth(method = "lm")

ld
```

Cadence is the measure of how many times a runner's feet hit the ground per minute. A high cadence is typically associated with a faster pace. 
```{r cad_ap}
# Effect of Cadence on Average Pace
cad_ap <-garminRun %>% ggplot(aes(x=avg_run_cadence, y=avg_pace))+
  geom_point()+
  geom_smooth(method = "lm")

cad_ap
```

Aerobic TE is a measurement Garmin created to rate an aerobic effort. On a scale from 1-5, 5 is a maximum effort. This is good stress for the body, but requires a lot of rest time afterwards. 1 is minimal and typically associated with other types of exercise besides running. This 
```{r ae_ap}
# Effect of Harder Aerobic Effort on Average Pace
ae_ap<- garminRun %>% ggplot(aes(x=aerobic_TE, y=avg_pace))+
  geom_point()+
  geom_smooth(method = "lm")

ae_ap
```

Average heart rate may be another important variable in my project.
```{r hr_ap}
# Average Pace and Average Heart Rate
hr_ap <- garminRun %>% ggplot(aes(x=avg_hr, y = avg_pace))+
  geom_point()+
  geom_smooth(method = "lm")

hr_ap
```

Greater stride length seems to be associated with a greater pace. This seems counter-intuitive if thinking about cadence in this equations, but with good form and mechanics, greater cadence is more likely to be associated with greater stride length.
```{r st_ap}
# Stride and Average Pace
st_ap <- garminRun %>% ggplot(aes(x=avg_stride, y = avg_pace))+
  geom_point()+
  geom_smooth(method = "lm")

st_ap
```

#### Other important variables

Correlation between cadence and stride
```{r cadence_stride}
ca_stride <- garminRun %>% ggplot(aes(x=avg_run_cadence, y=avg_stride))+
  geom_point()+
  geom_smooth(method = "lm")

ca_stride
```

Living in the Southern US, we have to deal with high temperatures. Marathons typically aren't held in the summer for a reason. Excessive heat is not only known to decrease performance, but can be dangerous. Although it can't be totally avoided, I try not to run when it's too hot out.
```{r temp_dist}
# Temperature
# I'm less likely to run far when it gets hot out. 
fit1 <- lm(distance ~ temperature, run_df)
summary(fit1)

temp_dist <- run_df %>% ggplot(aes(x=temperature, y = distance))+
  geom_point()+
  geom_smooth(method = "lm")

temp_dist
```

```{r temp_pace}
temp_pace <- run_df %>% ggplot(aes(x=temperature, y = avg_pace))+
  geom_point()+
  geom_smooth(method = "lm")

temp_pace
```

Hill training is crucial for success in any race and research shows that hill intervals can better prepare runners than any other type of training. 
```{r hr_ascent_plot}
#avg_hr, total_ascent
hr_ascent <- lm(avg_hr~total_ascent,garminRun)
summary(hr_ascent)

hr_ascent_plot <-garminRun %>% ggplot(aes(x=avg_hr, y = total_ascent))+
  geom_point()+
  geom_smooth(method = "lm")

hr_ascent_plot
```

```{r ae_ta}
ae_ta <- garminRun %>% ggplot(aes(x=aerobic_TE, y=total_ascent))+
  geom_point()+
  geom_smooth(method = "lm")

ae_ta
```